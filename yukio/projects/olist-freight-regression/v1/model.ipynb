{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3baa96b9",
   "metadata": {},
   "source": [
    "# Freight Value Prediction Model\n",
    "This notebook focuses on building and evaluating machine learning models to predict freight values using the Olist dataset. The steps include data preparation, feature engineering, model training, evaluation, and fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a206f9",
   "metadata": {},
   "source": [
    "## 1. Importing Required Libraries\n",
    "We start by importing the necessary libraries for data manipulation, visualization, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed7adfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from category_encoders import CatBoostEncoder\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import optuna as opt\n",
    "import math\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ea7eef",
   "metadata": {},
   "source": [
    "## 2. Loading the Dataset\n",
    "We load the preprocessed dataset `df_final.csv` from the `data` directory. This dataset contains features and the target variable `freight_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdef6767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>product_length_cm</th>\n",
       "      <th>product_height_cm</th>\n",
       "      <th>product_width_cm</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>review_score</th>\n",
       "      <th>...</th>\n",
       "      <th>volume</th>\n",
       "      <th>density</th>\n",
       "      <th>actual_delivery_time</th>\n",
       "      <th>estimated_delivery_time</th>\n",
       "      <th>approval_order_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>purchase_month</th>\n",
       "      <th>purchase_day_of_week</th>\n",
       "      <th>black_friday</th>\n",
       "      <th>christmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.99</td>\n",
       "      <td>8.72</td>\n",
       "      <td>utilidades_domesticas</td>\n",
       "      <td>500.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>0.253036</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.566632</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118.70</td>\n",
       "      <td>22.76</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>400.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>barreiras</td>\n",
       "      <td>BA</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4693.0</td>\n",
       "      <td>0.085233</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>847.437333</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159.90</td>\n",
       "      <td>19.22</td>\n",
       "      <td>automotivo</td>\n",
       "      <td>420.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>vianopolis</td>\n",
       "      <td>GO</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9576.0</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512.100044</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.00</td>\n",
       "      <td>27.20</td>\n",
       "      <td>pet_shop</td>\n",
       "      <td>450.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>sao goncalo do amarante</td>\n",
       "      <td>RN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1816.085655</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.90</td>\n",
       "      <td>8.72</td>\n",
       "      <td>papelaria</td>\n",
       "      <td>250.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>santo andre</td>\n",
       "      <td>SP</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>11475.0</td>\n",
       "      <td>0.021786</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.684401</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  freight_value  product_category_name  product_weight_g  \\\n",
       "0   29.99           8.72  utilidades_domesticas             500.0   \n",
       "1  118.70          22.76             perfumaria             400.0   \n",
       "2  159.90          19.22             automotivo             420.0   \n",
       "3   45.00          27.20               pet_shop             450.0   \n",
       "4   19.90           8.72              papelaria             250.0   \n",
       "\n",
       "   product_length_cm  product_height_cm  product_width_cm  \\\n",
       "0               19.0                8.0              13.0   \n",
       "1               19.0               13.0              19.0   \n",
       "2               24.0               19.0              21.0   \n",
       "3               30.0               10.0              20.0   \n",
       "4               51.0               15.0              15.0   \n",
       "\n",
       "             customer_city customer_state  review_score  ...   volume  \\\n",
       "0                sao paulo             SP             4  ...   1976.0   \n",
       "1                barreiras             BA             4  ...   4693.0   \n",
       "2               vianopolis             GO             5  ...   9576.0   \n",
       "3  sao goncalo do amarante             RN             5  ...   6000.0   \n",
       "4              santo andre             SP             5  ...  11475.0   \n",
       "\n",
       "    density  actual_delivery_time  estimated_delivery_time  \\\n",
       "0  0.253036                   8.0                       15   \n",
       "1  0.085233                  13.0                       19   \n",
       "2  0.043860                   9.0                       26   \n",
       "3  0.075000                  13.0                       26   \n",
       "4  0.021786                   2.0                       12   \n",
       "\n",
       "   approval_order_time     distance  purchase_month  purchase_day_of_week  \\\n",
       "0                  0.0    18.566632              10                     0   \n",
       "1                  1.0   847.437333               7                     1   \n",
       "2                  0.0   512.100044               8                     2   \n",
       "3                  0.0  1816.085655              11                     5   \n",
       "4                  0.0    29.684401               2                     1   \n",
       "\n",
       "   black_friday  christmas  \n",
       "0             0          0  \n",
       "1             0          0  \n",
       "2             0          0  \n",
       "3             0          0  \n",
       "4             0          0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the base directory for the data files\n",
    "data_dir = 'data'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(os.path.join(data_dir, 'df_final.csv'))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9cff3b",
   "metadata": {},
   "source": [
    "## 3. Splitting Data into Features and Target\n",
    "We separate the dataset into features (`X`) and the target variable (`y`), which is `freight_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aecfa2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting in X and Y\n",
    "X = df.drop(columns='freight_value', axis=1)\n",
    "y = df.freight_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da626fab",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split\n",
    "We split the data into training and testing sets using an 80-20 split to evaluate the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b7ee63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting in train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f469e2",
   "metadata": {},
   "source": [
    "## 5. Initializing Models\n",
    "We initialize multiple regression models, including XGBoost, LightGBM, CatBoost, and Decision Tree, with default or predefined hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "616a435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing models\n",
    "model_XGBoost = XGBRegressor(n_estimators = 1000, max_depth = 8, learning_rate = 1e-3, random_state = 0)\n",
    "model_LightGBM = LGBMRegressor(n_estimators = 1000, max_depth = 8, num_leaves = 2^8, learning_rate = 1e-3, n_jobs = -1, verbose = -1, random_state = 0)\n",
    "model_DecisionTree = DecisionTreeRegressor(random_state = 0, max_depth = 8, min_samples_split = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a1930",
   "metadata": {},
   "source": [
    "## 6. Feature Encoding and Importance\n",
    "We encode categorical features using CatBoostEncoder and calculate feature importance using permutation importance with the XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1693328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "\n",
    "encoder = CatBoostEncoder()\n",
    "X_train_encoded = X_train.copy()\n",
    "X_test_encoded = X_test.copy()\n",
    "\n",
    "for col in X_train_encoded.select_dtypes(include=['object']).columns:\n",
    "    X_train_encoded[col] = encoder.fit_transform(X_train_encoded[col], y_train)\n",
    "    X_test_encoded[col] = encoder.transform(X_test_encoded[col])\n",
    "\n",
    "model_XGBoost.fit(X_train_encoded, y_train)\n",
    "r = permutation_importance(model_XGBoost, X_test_encoded, y_test, n_repeats=30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66add077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>distance</td>\n",
       "      <td>0.211973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>volume</td>\n",
       "      <td>0.198656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>product_weight_g</td>\n",
       "      <td>0.178174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>price</td>\n",
       "      <td>0.080163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>customer_state</td>\n",
       "      <td>0.025644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>product_length_cm</td>\n",
       "      <td>0.022553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>seller_city</td>\n",
       "      <td>0.021714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>seller_state</td>\n",
       "      <td>0.013614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>product_width_cm</td>\n",
       "      <td>0.004467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>density</td>\n",
       "      <td>0.003321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>purchase_month</td>\n",
       "      <td>0.002923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product_category_name</td>\n",
       "      <td>0.001475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>customer_city</td>\n",
       "      <td>0.001295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>product_height_cm</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>actual_delivery_time</td>\n",
       "      <td>0.000642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>review_score</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>black_friday</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>christmas</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>purchase_day_of_week</td>\n",
       "      <td>-0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>approval_order_time</td>\n",
       "      <td>-0.000902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>estimated_delivery_time</td>\n",
       "      <td>-0.001062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature  importance\n",
       "16                 distance    0.211973\n",
       "11                   volume    0.198656\n",
       "2          product_weight_g    0.178174\n",
       "0                     price    0.080163\n",
       "7            customer_state    0.025644\n",
       "3         product_length_cm    0.022553\n",
       "9               seller_city    0.021714\n",
       "10             seller_state    0.013614\n",
       "5          product_width_cm    0.004467\n",
       "12                  density    0.003321\n",
       "17           purchase_month    0.002923\n",
       "1     product_category_name    0.001475\n",
       "6             customer_city    0.001295\n",
       "4         product_height_cm    0.001211\n",
       "13     actual_delivery_time    0.000642\n",
       "8              review_score    0.000312\n",
       "19             black_friday    0.000003\n",
       "20                christmas    0.000000\n",
       "18     purchase_day_of_week   -0.000202\n",
       "15      approval_order_time   -0.000902\n",
       "14  estimated_delivery_time   -0.001062"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.DataFrame({'Feature': X_test_encoded.columns, 'importance': r.importances_mean})\n",
    "importances = importances.sort_values(by='importance', ascending=False)\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e2047",
   "metadata": {},
   "source": [
    "## 7. Feature Selection\n",
    "Based on feature importance, we drop less important features to simplify the model and improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bceda8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "less_important_columns = ['purchase_day_of_week', 'approval_order_time', 'estimated_delivery_time', 'christmas', 'black_friday']\n",
    "\n",
    "X_train = X_train.drop(columns=less_important_columns)\n",
    "X_test = X_test.drop(columns=less_important_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d135ac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "\n",
    "encoder = CatBoostEncoder()\n",
    "X_train_encoded = X_train.copy()\n",
    "X_test_encoded = X_test.copy()\n",
    "\n",
    "for col in X_train_encoded.select_dtypes(include=['object']).columns:\n",
    "    X_train_encoded[col] = encoder.fit_transform(X_train_encoded[col], y_train)\n",
    "    X_test_encoded[col] = encoder.transform(X_test_encoded[col])\n",
    "\n",
    "model_XGBoost.fit(X_train_encoded, y_train)\n",
    "r_v2 = permutation_importance(model_XGBoost, X_test_encoded, y_test, n_repeats=30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a41b22ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>distance</td>\n",
       "      <td>0.211323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>volume</td>\n",
       "      <td>0.203850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>product_weight_g</td>\n",
       "      <td>0.182162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>price</td>\n",
       "      <td>0.090672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>customer_state</td>\n",
       "      <td>0.024785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>product_length_cm</td>\n",
       "      <td>0.024383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>seller_city</td>\n",
       "      <td>0.022433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>seller_state</td>\n",
       "      <td>0.012966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>product_width_cm</td>\n",
       "      <td>0.004509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>customer_city</td>\n",
       "      <td>0.003811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>purchase_month</td>\n",
       "      <td>0.002410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>density</td>\n",
       "      <td>0.001630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product_category_name</td>\n",
       "      <td>0.001497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>product_height_cm</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>actual_delivery_time</td>\n",
       "      <td>0.000855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>review_score</td>\n",
       "      <td>0.000339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Feature  importance\n",
       "14               distance    0.211323\n",
       "11                 volume    0.203850\n",
       "2        product_weight_g    0.182162\n",
       "0                   price    0.090672\n",
       "7          customer_state    0.024785\n",
       "3       product_length_cm    0.024383\n",
       "9             seller_city    0.022433\n",
       "10           seller_state    0.012966\n",
       "5        product_width_cm    0.004509\n",
       "6           customer_city    0.003811\n",
       "15         purchase_month    0.002410\n",
       "12                density    0.001630\n",
       "1   product_category_name    0.001497\n",
       "4       product_height_cm    0.001340\n",
       "13   actual_delivery_time    0.000855\n",
       "8            review_score    0.000339"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances_v2 = pd.DataFrame({'Feature': X_test_encoded.columns, 'importance': r_v2.importances_mean})\n",
    "importances_v2 = importances_v2.sort_values(by='importance', ascending=False)\n",
    "importances_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2493941a",
   "metadata": {},
   "source": [
    "## 8. Cross-Validation\n",
    "We perform k-fold cross-validation to evaluate the model's performance across multiple splits of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa76170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 1 ##########\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 5.044\n",
      "MSE: 98.518\n",
      "R2: 0.600\n",
      "########## Fold: 2 ##########\n",
      "MAE: 5.188\n",
      "MSE: 106.660\n",
      "R2: 0.597\n",
      "########## Fold: 3 ##########\n",
      "MAE: 5.146\n",
      "MSE: 97.921\n",
      "R2: 0.605\n",
      "########## Fold: 4 ##########\n",
      "MAE: 5.078\n",
      "MSE: 112.953\n",
      "R2: 0.584\n",
      "########## Fold: 5 ##########\n",
      "MAE: 4.990\n",
      "MSE: 88.761\n",
      "R2: 0.620\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "folds = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "absolute_errors = list()\n",
    "squared_errors = list()\n",
    "r2 = list()\n",
    "\n",
    "for k, (train_index, test_index) in enumerate(folds.split(X, y)):\n",
    "    \n",
    "    print(\"#\"*10 + f\" Fold: {k+1} \" + \"#\"*10)\n",
    "    \n",
    "    X_train_internal, y_train_internal = X.iloc[train_index, :], y.iloc[train_index]\n",
    "    X_test_internal, y_test_internal = X.iloc[test_index, :], y.iloc[test_index]\n",
    "\n",
    "    encoder = CatBoostEncoder()\n",
    "    \n",
    "    cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    num_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "    cat_pipeline = Pipeline([('encoder', encoder), ('imputer', cat_imputer)])\n",
    "    num_pipeline = Pipeline([('imputer', num_imputer)])\n",
    "\n",
    "    cat_cols = X_train_internal.select_dtypes(include=['object']).columns\n",
    "    num_cols = X_train_internal.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "    X_train_internal[cat_cols] = cat_pipeline.fit_transform(X_train_internal[cat_cols], y_train_internal)\n",
    "    X_train_internal[num_cols] = num_pipeline.fit_transform(X_train_internal[num_cols])\n",
    "\n",
    "    X_test_internal[cat_cols] = cat_pipeline.transform(X_test_internal[cat_cols])\n",
    "    X_test_internal[num_cols] = num_pipeline.transform(X_test_internal[num_cols])\n",
    "\n",
    "    model_XGBoost.fit(X_train_internal, y_train_internal)\n",
    "    y_pred = model_XGBoost.predict(X_test_internal)\n",
    "    r2score = r2_score(y_test_internal, y_pred)\n",
    "    mse = mean_squared_error(y_test_internal, y_pred)\n",
    "    mae = mean_absolute_error(y_test_internal, y_pred)\n",
    "\n",
    "    absolute_errors.append(mae)\n",
    "    squared_errors.append(mse)\n",
    "    r2.append(r2score)\n",
    "\n",
    "    print(f'MAE: {mae:.3f}')\n",
    "    print(f'MSE: {mse:.3f}')\n",
    "    print(f'R2: {r2score:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86730329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Displaying Average of Obtained Metrics : #####\n",
      "Average MAE: 5.089 +/- 0.071\n",
      "Average MSE: 100.963 +/- 8.250\n",
      "Average R2: 0.601 +/- 0.012\n"
     ]
    }
   ],
   "source": [
    "absolute_errors = np.array(absolute_errors)\n",
    "squared_errors = np.array(squared_errors)\n",
    "r2 = np.array(r2)\n",
    "\n",
    "avg_mae = np.mean(absolute_errors)\n",
    "avg_mse = np.mean(squared_errors)\n",
    "avg_r2 = np.mean(r2)\n",
    "\n",
    "std_mae = np.std(absolute_errors)\n",
    "std_mse = np.std(squared_errors)\n",
    "std_r2 = np.std(r2)\n",
    "\n",
    "print(\"#\"*5 + f\" Displaying Average of Obtained Metrics : \" + \"#\"*5)\n",
    "print(f\"Average MAE: {avg_mae:.3f} +/- {std_mae:.3f}\")\n",
    "print(f'Average MSE: {avg_mse:.3f} +/- {std_mse:.3f}')\n",
    "print(f'Average R2: {avg_r2:.3f} +/- {std_r2:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c547e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X, y, model, k):\n",
    "    folds = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    absolute_errors = list()\n",
    "    squared_errors = list()\n",
    "    r2 = list()\n",
    "\n",
    "    for k, (train_index, test_index) in enumerate(folds.split(X, y)):\n",
    "        \n",
    "        print(\"#\"*10 + f\" Fold: {k+1} \" + \"#\"*10)\n",
    "        \n",
    "        X_train_internal, y_train_internal = X.iloc[train_index, :], y.iloc[train_index]\n",
    "        X_test_internal, y_test_internal = X.iloc[test_index, :], y.iloc[test_index]\n",
    "\n",
    "        encoder = CatBoostEncoder()\n",
    "        \n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "        cat_pipeline = Pipeline([('encoder', encoder), ('imputer', cat_imputer)])\n",
    "        num_pipeline = Pipeline([('imputer', num_imputer)])\n",
    "\n",
    "        cat_cols = X_train_internal.select_dtypes(include=['object']).columns\n",
    "        num_cols = X_train_internal.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "        X_train_internal[cat_cols] = cat_pipeline.fit_transform(X_train_internal[cat_cols], y_train_internal)\n",
    "        X_train_internal[num_cols] = num_pipeline.fit_transform(X_train_internal[num_cols])\n",
    "\n",
    "        X_test_internal[cat_cols] = cat_pipeline.transform(X_test_internal[cat_cols])\n",
    "        X_test_internal[num_cols] = num_pipeline.transform(X_test_internal[num_cols])\n",
    "\n",
    "        model.fit(X_train_internal, y_train_internal)\n",
    "        y_pred = model.predict(X_test_internal)\n",
    "\n",
    "        r2score = r2_score(y_test_internal, y_pred)\n",
    "        mse = mean_squared_error(y_test_internal, y_pred)\n",
    "        mae = mean_absolute_error(y_test_internal, y_pred)\n",
    "\n",
    "        absolute_errors.append(mae)\n",
    "        squared_errors.append(mse)\n",
    "        r2.append(r2score)\n",
    "\n",
    "        print(f'MAE: {mae:.3f}')\n",
    "        print(f'MSE: {mse:.3f}')\n",
    "        print(f'R2: {r2score:.3f}')\n",
    "    \n",
    "    absolute_errors = np.array(absolute_errors)\n",
    "    squared_errors = np.array(squared_errors)\n",
    "    r2 = np.array(r2)\n",
    "\n",
    "    avg_mae = np.mean(absolute_errors)\n",
    "    avg_mse = np.mean(squared_errors)\n",
    "    avg_r2 = np.mean(r2)\n",
    "\n",
    "    std_mae = np.std(absolute_errors)\n",
    "    std_mse = np.std(squared_errors)\n",
    "    std_r2 = np.std(r2)\n",
    "\n",
    "    print(\"#\"*5 + f\" Displaying Average of Obtained Metrics : \" + \"#\"*5)\n",
    "    print(f\"Average MAE: {avg_mae:.3f} +/- {std_mae:.3f}\")\n",
    "    print(f'Average MSE: {avg_mse:.3f} +/- {std_mse:.3f}')\n",
    "    print(f'Average R2: {avg_r2:.3f} +/- {std_r2:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b1fbc",
   "metadata": {},
   "source": [
    "### Modelo XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93155869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo XGBoost\n",
    "# cross_validation(X, y, model_XGBoost, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15bec2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 14:40:13 WARNING mlflow.utils.autologging_utils: MLflow xgboost autologging is known to be compatible with 1.4.2 <= xgboost <= 2.1.4, but the installed version is 3.0.0. If you encounter errors during autologging, try upgrading / downgrading xgboost to a compatible version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 1 ##########\n",
      "MAE: 5.044\n",
      "MSE: 98.518\n",
      "R2: 0.600\n",
      "########## Fold: 2 ##########\n",
      "MAE: 5.188\n",
      "MSE: 106.660\n",
      "R2: 0.597\n",
      "########## Fold: 3 ##########\n",
      "MAE: 5.146\n",
      "MSE: 97.921\n",
      "R2: 0.605\n",
      "########## Fold: 4 ##########\n",
      "MAE: 5.078\n",
      "MSE: 112.953\n",
      "R2: 0.584\n",
      "########## Fold: 5 ##########\n",
      "MAE: 4.990\n",
      "MSE: 88.761\n",
      "R2: 0.620\n",
      "##### Displaying Average of Obtained Metrics : #####\n",
      "Average MAE: 5.089 +/- 0.071\n",
      "Average MSE: 100.963 +/- 8.250\n",
      "Average R2: 0.601 +/- 0.012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/18 14:41:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run XGBoost Cross-Validation at: http://localhost:5000/#/experiments/535394779431182411/runs/0959333936e34847a2765182e7305baa\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    }
   ],
   "source": [
    "cross_validation_with_mlflow(X, y, model_XGBoost, k=5, model_name=\"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db2bc48",
   "metadata": {},
   "source": [
    "### Modelo LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c1f731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 1 ##########\n",
      "MAE: 5.664\n",
      "MSE: 120.227\n",
      "R2: 0.511\n",
      "########## Fold: 2 ##########\n",
      "MAE: 5.827\n",
      "MSE: 128.344\n",
      "R2: 0.515\n",
      "########## Fold: 3 ##########\n",
      "MAE: 5.773\n",
      "MSE: 119.646\n",
      "R2: 0.517\n",
      "########## Fold: 4 ##########\n",
      "MAE: 5.715\n",
      "MSE: 136.550\n",
      "R2: 0.497\n",
      "########## Fold: 5 ##########\n",
      "MAE: 5.612\n",
      "MSE: 108.576\n",
      "R2: 0.535\n",
      "##### Displaying Average of Obtained Metrics : #####\n",
      "Average MAE: 5.718 +/- 0.076\n",
      "Average MSE: 122.669 +/- 9.366\n",
      "Average R2: 0.515 +/- 0.012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/18 14:42:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run LightGBM Cross-Validation at: http://localhost:5000/#/experiments/535394779431182411/runs/56c657c45fb04961af4f9b58ff06c9d1\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    }
   ],
   "source": [
    "# Modelo LightGBM\n",
    "cross_validation(X, y, model_LightGBM, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5ca5e0",
   "metadata": {},
   "source": [
    "### Modelo Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae495d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Decision Tree\n",
    "cross_validation(X, y, model_DecisionTree, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58121e7e",
   "metadata": {},
   "source": [
    "## 9. Fine-Tuning\n",
    "We use Optuna to perform hyperparameter optimization for the XGBoost model to improve its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a24d8dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInit signature:\u001b[39m\n",
      "XGBRegressor(\n",
      "    *,\n",
      "    objective: Union[str, xgboost.sklearn._SklObjWProto, Callable[[Any, Any], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = \u001b[33m'reg:squarederror'\u001b[39m,\n",
      "    **kwargs: Any,\n",
      ") -> \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mDocstring:\u001b[39m     \n",
      "Implementation of the scikit-learn API for XGBoost regression.\n",
      "See :doc:`/python/sklearn_estimator` for more information.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "\n",
      "    n_estimators : typing.Optional[int]\n",
      "        Number of gradient boosted trees.  Equivalent to number of boosting\n",
      "        rounds.\n",
      "\n",
      "    max_depth :  typing.Optional[int]\n",
      "\n",
      "        Maximum tree depth for base learners.\n",
      "\n",
      "    max_leaves : typing.Optional[int]\n",
      "\n",
      "        Maximum number of leaves; 0 indicates no limit.\n",
      "\n",
      "    max_bin : typing.Optional[int]\n",
      "\n",
      "        If using histogram-based algorithm, maximum number of bins per feature\n",
      "\n",
      "    grow_policy : typing.Optional[str]\n",
      "\n",
      "        Tree growing policy.\n",
      "\n",
      "        - depthwise: Favors splitting at nodes closest to the node,\n",
      "        - lossguide: Favors splitting at nodes with highest loss change.\n",
      "\n",
      "    learning_rate : typing.Optional[float]\n",
      "\n",
      "        Boosting learning rate (xgb's \"eta\")\n",
      "\n",
      "    verbosity : typing.Optional[int]\n",
      "\n",
      "        The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
      "\n",
      "    objective : typing.Union[str, xgboost.sklearn._SklObjWProto, typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]\n",
      "\n",
      "        Specify the learning task and the corresponding learning objective or a custom\n",
      "        objective function to be used.\n",
      "\n",
      "        For custom objective, see :doc:`/tutorials/custom_metric_obj` and\n",
      "        :ref:`custom-obj-metric` for more information, along with the end note for\n",
      "        function signatures.\n",
      "\n",
      "    booster: typing.Optional[str]\n",
      "\n",
      "        Specify which booster to use: ``gbtree``, ``gblinear`` or ``dart``.\n",
      "\n",
      "    tree_method : typing.Optional[str]\n",
      "\n",
      "        Specify which tree method to use.  Default to auto.  If this parameter is set to\n",
      "        default, XGBoost will choose the most conservative option available.  It's\n",
      "        recommended to study this option from the parameters document :doc:`tree method\n",
      "        </treemethod>`\n",
      "\n",
      "    n_jobs : typing.Optional[int]\n",
      "\n",
      "        Number of parallel threads used to run xgboost.  When used with other\n",
      "        Scikit-Learn algorithms like grid search, you may choose which algorithm to\n",
      "        parallelize and balance the threads.  Creating thread contention will\n",
      "        significantly slow down both algorithms.\n",
      "\n",
      "    gamma : typing.Optional[float]\n",
      "\n",
      "        (min_split_loss) Minimum loss reduction required to make a further partition on\n",
      "        a leaf node of the tree.\n",
      "\n",
      "    min_child_weight : typing.Optional[float]\n",
      "\n",
      "        Minimum sum of instance weight(hessian) needed in a child.\n",
      "\n",
      "    max_delta_step : typing.Optional[float]\n",
      "\n",
      "        Maximum delta step we allow each tree's weight estimation to be.\n",
      "\n",
      "    subsample : typing.Optional[float]\n",
      "\n",
      "        Subsample ratio of the training instance.\n",
      "\n",
      "    sampling_method : typing.Optional[str]\n",
      "\n",
      "        Sampling method. Used only by the GPU version of ``hist`` tree method.\n",
      "\n",
      "        - ``uniform``: Select random training instances uniformly.\n",
      "        - ``gradient_based``: Select random training instances with higher probability\n",
      "            when the gradient and hessian are larger. (cf. CatBoost)\n",
      "\n",
      "    colsample_bytree : typing.Optional[float]\n",
      "\n",
      "        Subsample ratio of columns when constructing each tree.\n",
      "\n",
      "    colsample_bylevel : typing.Optional[float]\n",
      "\n",
      "        Subsample ratio of columns for each level.\n",
      "\n",
      "    colsample_bynode : typing.Optional[float]\n",
      "\n",
      "        Subsample ratio of columns for each split.\n",
      "\n",
      "    reg_alpha : typing.Optional[float]\n",
      "\n",
      "        L1 regularization term on weights (xgb's alpha).\n",
      "\n",
      "    reg_lambda : typing.Optional[float]\n",
      "\n",
      "        L2 regularization term on weights (xgb's lambda).\n",
      "\n",
      "    scale_pos_weight : typing.Optional[float]\n",
      "        Balancing of positive and negative weights.\n",
      "\n",
      "    base_score : typing.Optional[float]\n",
      "\n",
      "        The initial prediction score of all instances, global bias.\n",
      "\n",
      "    random_state : typing.Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType]\n",
      "\n",
      "        Random number seed.\n",
      "\n",
      "        .. note::\n",
      "\n",
      "           Using gblinear booster with shotgun updater is nondeterministic as\n",
      "           it uses Hogwild algorithm.\n",
      "\n",
      "    missing : float\n",
      "\n",
      "        Value in the data which needs to be present as a missing value. Default to\n",
      "        :py:data:`numpy.nan`.\n",
      "\n",
      "    num_parallel_tree: typing.Optional[int]\n",
      "\n",
      "        Used for boosting random forest.\n",
      "\n",
      "    monotone_constraints : typing.Union[typing.Dict[str, int], str, NoneType]\n",
      "\n",
      "        Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`\n",
      "        for more information.\n",
      "\n",
      "    interaction_constraints : typing.Union[str, typing.List[typing.Tuple[str]], NoneType]\n",
      "\n",
      "        Constraints for interaction representing permitted interactions.  The\n",
      "        constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,\n",
      "        3, 4]]``, where each inner list is a group of indices of features that are\n",
      "        allowed to interact with each other.  See :doc:`tutorial\n",
      "        </tutorials/feature_interaction_constraint>` for more information\n",
      "\n",
      "    importance_type: typing.Optional[str]\n",
      "\n",
      "        The feature importance type for the feature_importances\\_ property:\n",
      "\n",
      "        * For tree model, it's either \"gain\", \"weight\", \"cover\", \"total_gain\" or\n",
      "          \"total_cover\".\n",
      "        * For linear model, only \"weight\" is defined and it's the normalized\n",
      "          coefficients without bias.\n",
      "\n",
      "    device : typing.Optional[str]\n",
      "\n",
      "        .. versionadded:: 2.0.0\n",
      "\n",
      "        Device ordinal, available options are `cpu`, `cuda`, and `gpu`.\n",
      "\n",
      "    validate_parameters : typing.Optional[bool]\n",
      "\n",
      "        Give warnings for unknown parameter.\n",
      "\n",
      "    enable_categorical : bool\n",
      "\n",
      "        See the same parameter of :py:class:`DMatrix` for details.\n",
      "\n",
      "    feature_types : typing.Optional[typing.Sequence[str]]\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        Used for specifying feature types without constructing a dataframe. See\n",
      "        :py:class:`DMatrix` for details.\n",
      "\n",
      "    feature_weights : Optional[ArrayLike]\n",
      "\n",
      "        Weight for each feature, defines the probability of each feature being selected\n",
      "        when colsample is being used.  All values must be greater than 0, otherwise a\n",
      "        `ValueError` is thrown.\n",
      "\n",
      "    max_cat_to_onehot : Optional[int]\n",
      "\n",
      "        .. versionadded:: 1.6.0\n",
      "\n",
      "        .. note:: This parameter is experimental\n",
      "\n",
      "        A threshold for deciding whether XGBoost should use one-hot encoding based split\n",
      "        for categorical data.  When number of categories is lesser than the threshold\n",
      "        then one-hot encoding is chosen, otherwise the categories will be partitioned\n",
      "        into children nodes. Also, `enable_categorical` needs to be set to have\n",
      "        categorical feature support. See :doc:`Categorical Data\n",
      "        </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      "\n",
      "    max_cat_threshold : typing.Optional[int]\n",
      "\n",
      "        .. versionadded:: 1.7.0\n",
      "\n",
      "        .. note:: This parameter is experimental\n",
      "\n",
      "        Maximum number of categories considered for each split. Used only by\n",
      "        partition-based splits for preventing over-fitting. Also, `enable_categorical`\n",
      "        needs to be set to have categorical feature support. See :doc:`Categorical Data\n",
      "        </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      "\n",
      "    multi_strategy : typing.Optional[str]\n",
      "\n",
      "        .. versionadded:: 2.0.0\n",
      "\n",
      "        .. note:: This parameter is working-in-progress.\n",
      "\n",
      "        The strategy used for training multi-target models, including multi-target\n",
      "        regression and multi-class classification. See :doc:`/tutorials/multioutput` for\n",
      "        more information.\n",
      "\n",
      "        - ``one_output_per_tree``: One model for each target.\n",
      "        - ``multi_output_tree``:  Use multi-target trees.\n",
      "\n",
      "    eval_metric : typing.Union[str, typing.List[str], typing.Callable, NoneType]\n",
      "\n",
      "        .. versionadded:: 1.6.0\n",
      "\n",
      "        Metric used for monitoring the training result and early stopping.  It can be a\n",
      "        string or list of strings as names of predefined metric in XGBoost (See\n",
      "        :doc:`/parameter`), one of the metrics in :py:mod:`sklearn.metrics`, or any\n",
      "        other user defined metric that looks like `sklearn.metrics`.\n",
      "\n",
      "        If custom objective is also provided, then custom metric should implement the\n",
      "        corresponding reverse link function.\n",
      "\n",
      "        Unlike the `scoring` parameter commonly used in scikit-learn, when a callable\n",
      "        object is provided, it's assumed to be a cost function and by default XGBoost\n",
      "        will minimize the result during early stopping.\n",
      "\n",
      "        For advanced usage on Early stopping like directly choosing to maximize instead\n",
      "        of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.\n",
      "\n",
      "        See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more\n",
      "        information.\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            from sklearn.datasets import load_diabetes\n",
      "            from sklearn.metrics import mean_absolute_error\n",
      "            X, y = load_diabetes(return_X_y=True)\n",
      "            reg = xgb.XGBRegressor(\n",
      "                tree_method=\"hist\",\n",
      "                eval_metric=mean_absolute_error,\n",
      "            )\n",
      "            reg.fit(X, y, eval_set=[(X, y)])\n",
      "\n",
      "    early_stopping_rounds : typing.Optional[int]\n",
      "\n",
      "        .. versionadded:: 1.6.0\n",
      "\n",
      "        - Activates early stopping. Validation metric needs to improve at least once in\n",
      "          every **early_stopping_rounds** round(s) to continue training.  Requires at\n",
      "          least one item in **eval_set** in :py:meth:`fit`.\n",
      "\n",
      "        - If early stopping occurs, the model will have two additional attributes:\n",
      "          :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the\n",
      "          :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal\n",
      "          number of trees during inference. If users want to access the full model\n",
      "          (including trees built after early stopping), they can specify the\n",
      "          `iteration_range` in these inference methods. In addition, other utilities\n",
      "          like model plotting can also use the entire model.\n",
      "\n",
      "        - If you prefer to discard the trees after `best_iteration`, consider using the\n",
      "          callback function :py:class:`xgboost.callback.EarlyStopping`.\n",
      "\n",
      "        - If there's more than one item in **eval_set**, the last entry will be used for\n",
      "          early stopping.  If there's more than one metric in **eval_metric**, the last\n",
      "          metric will be used for early stopping.\n",
      "\n",
      "    callbacks : typing.Optional[typing.List[xgboost.callback.TrainingCallback]]\n",
      "\n",
      "        List of callback functions that are applied at end of each iteration.\n",
      "        It is possible to use predefined callbacks by using\n",
      "        :ref:`Callback API <callback_api>`.\n",
      "\n",
      "        .. note::\n",
      "\n",
      "           States in callback are not preserved during training, which means callback\n",
      "           objects can not be reused for multiple training sessions without\n",
      "           reinitialization or deepcopy.\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            for params in parameters_grid:\n",
      "                # be sure to (re)initialize the callbacks before each run\n",
      "                callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]\n",
      "                reg = xgboost.XGBRegressor(**params, callbacks=callbacks)\n",
      "                reg.fit(X, y)\n",
      "\n",
      "    kwargs : typing.Optional[typing.Any]\n",
      "\n",
      "        Keyword arguments for XGBoost Booster object.  Full documentation of parameters\n",
      "        can be found :doc:`here </parameter>`.\n",
      "        Attempting to set a parameter via the constructor args and \\*\\*kwargs\n",
      "        dict simultaneously will result in a TypeError.\n",
      "\n",
      "        .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
      "\n",
      "            \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee\n",
      "            that parameters passed via this argument will interact properly\n",
      "            with scikit-learn.\n",
      "\n",
      "        .. note::  Custom objective function\n",
      "\n",
      "            A custom objective function can be provided for the ``objective``\n",
      "            parameter. In this case, it should have the signature ``objective(y_true,\n",
      "            y_pred) -> [grad, hess]`` or ``objective(y_true, y_pred, *, sample_weight)\n",
      "            -> [grad, hess]``:\n",
      "\n",
      "            y_true: array_like of shape [n_samples]\n",
      "                The target values\n",
      "            y_pred: array_like of shape [n_samples]\n",
      "                The predicted values\n",
      "            sample_weight :\n",
      "                Optional sample weights.\n",
      "\n",
      "            grad: array_like of shape [n_samples]\n",
      "                The value of the gradient for each sample point.\n",
      "            hess: array_like of shape [n_samples]\n",
      "                The value of the second derivative for each sample point\n",
      "\n",
      "            Note that, if the custom objective produces negative values for\n",
      "            the Hessian, these will be clipped. If the objective is non-convex,\n",
      "            one might also consider using the expected Hessian (Fisher\n",
      "            information) instead.\n",
      "\u001b[31mFile:\u001b[39m           /opt/conda/envs/olist-freight/lib/python3.13/site-packages/xgboost/sklearn.py\n",
      "\u001b[31mType:\u001b[39m           type\n",
      "\u001b[31mSubclasses:\u001b[39m     XGBRFRegressor"
     ]
    }
   ],
   "source": [
    "?XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b05d0a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-18 15:17:22,694] A new study created in memory with name: no-name-0c3bb4f5-7a75-4b8f-8360-5542ee3aeb87\n",
      "2025/04/18 15:17:22 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '328795bf6cf744a0987713588a0e3bfa', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 1 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:17:23 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/04/18 15:17:26 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'f66aac0007c84634865853e865e96a1f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run debonair-mouse-545 at: http://localhost:5000/#/experiments/535394779431182411/runs/328795bf6cf744a0987713588a0e3bfa\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:17:26 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2025/04/18 15:17:26 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run valuable-bass-654 at: http://localhost:5000/#/experiments/535394779431182411/runs/f66aac0007c84634865853e865e96a1f\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:17:29 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8524486f365941aca9b32e90567d2dfe', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run sedate-fly-98 at: http://localhost:5000/#/experiments/535394779431182411/runs/8524486f365941aca9b32e90567d2dfe\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:17:43 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '957e7168f7864e989ee03bdf5ea6a85c', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 2 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:17:44 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/04/18 15:17:46 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'e2c683a6329841bc89590a24ef2ec685', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run bustling-horse-116 at: http://localhost:5000/#/experiments/535394779431182411/runs/957e7168f7864e989ee03bdf5ea6a85c\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:17:47 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2025/04/18 15:17:47 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run mysterious-conch-600 at: http://localhost:5000/#/experiments/535394779431182411/runs/e2c683a6329841bc89590a24ef2ec685\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:17:50 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'a1c36534d82248a4a669254eec26ee1c', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run traveling-hare-891 at: http://localhost:5000/#/experiments/535394779431182411/runs/a1c36534d82248a4a669254eec26ee1c\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:18:03 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '5b5382df27d34d43a7d71580e19210f7', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 3 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:18:04 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/04/18 15:18:07 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '6c19d3d0efb745db84b80a31b50407de', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run sedate-fly-826 at: http://localhost:5000/#/experiments/535394779431182411/runs/5b5382df27d34d43a7d71580e19210f7\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:18:07 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2025/04/18 15:18:07 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run painted-bug-375 at: http://localhost:5000/#/experiments/535394779431182411/runs/6c19d3d0efb745db84b80a31b50407de\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:18:10 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'cf95535fa0c842eb9e00090babf9c044', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run carefree-swan-788 at: http://localhost:5000/#/experiments/535394779431182411/runs/cf95535fa0c842eb9e00090babf9c044\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:18:23 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd25df08390b241ac88033e22202b00d1', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 4 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:18:24 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/04/18 15:18:27 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '28648ad3ebe74152b2bbee18c2fdc19e', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run able-newt-806 at: http://localhost:5000/#/experiments/535394779431182411/runs/d25df08390b241ac88033e22202b00d1\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:18:27 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2025/04/18 15:18:27 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run indecisive-wren-794 at: http://localhost:5000/#/experiments/535394779431182411/runs/28648ad3ebe74152b2bbee18c2fdc19e\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:18:30 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd7876829d72a43ceb31b5dfbd5bf8e53', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run overjoyed-sheep-309 at: http://localhost:5000/#/experiments/535394779431182411/runs/d7876829d72a43ceb31b5dfbd5bf8e53\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:18:45 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'a829cba16f764bcd8cf7def70d60ee62', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 5 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:18:46 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/04/18 15:18:48 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'e26e6b38968749319694acbc5d676dd3', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run agreeable-calf-168 at: http://localhost:5000/#/experiments/535394779431182411/runs/a829cba16f764bcd8cf7def70d60ee62\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:18:49 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2025/04/18 15:18:49 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run funny-sow-515 at: http://localhost:5000/#/experiments/535394779431182411/runs/e26e6b38968749319694acbc5d676dd3\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:18:52 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '3a1d051ffe5948adb4f68d4a92cd87d0', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run dashing-newt-487 at: http://localhost:5000/#/experiments/535394779431182411/runs/3a1d051ffe5948adb4f68d4a92cd87d0\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-18 15:19:05,468] Trial 0 finished with value: 100.96271617963595 and parameters: {'learning_rate': 0.002827571420648799, 'max_depth': 2, 'subsample': 0.9, 'colsample_bytree': 0.8, 'min_child_weight': 6}. Best is trial 0 with value: 100.96271617963595.\n",
      "2025/04/18 15:19:05 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'c04bd9b11ed64580a2390b54dc6518d0', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 1 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:19:06 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/04/18 15:19:09 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '16ed098cf59443dd900def64574b27d4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run sedate-hare-187 at: http://localhost:5000/#/experiments/535394779431182411/runs/c04bd9b11ed64580a2390b54dc6518d0\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:19:09 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2025/04/18 15:19:09 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run crawling-rat-57 at: http://localhost:5000/#/experiments/535394779431182411/runs/16ed098cf59443dd900def64574b27d4\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:19:12 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0e0e00b0852b4f67ad1801e2de5bc530', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run polite-ray-995 at: http://localhost:5000/#/experiments/535394779431182411/runs/0e0e00b0852b4f67ad1801e2de5bc530\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:19:25 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'efdb0705c3ac44ec9a7896a01a873066', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 2 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:19:26 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/04/18 15:19:29 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0649b59d914749bcae1073bdff1bef6d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run brawny-robin-391 at: http://localhost:5000/#/experiments/535394779431182411/runs/efdb0705c3ac44ec9a7896a01a873066\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:19:30 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2025/04/18 15:19:30 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run bouncy-donkey-991 at: http://localhost:5000/#/experiments/535394779431182411/runs/0649b59d914749bcae1073bdff1bef6d\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:19:33 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '01d5367ed2894e5ba7c3a7d3b7353aae', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run nebulous-hare-43 at: http://localhost:5000/#/experiments/535394779431182411/runs/01d5367ed2894e5ba7c3a7d3b7353aae\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:19:46 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8a23a210b8c74b728ed1e380e0edbcbd', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 3 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:19:47 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/04/18 15:19:50 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '811a7ade2c9044ec8c0a993d20af8fe1', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run youthful-shrew-214 at: http://localhost:5000/#/experiments/535394779431182411/runs/8a23a210b8c74b728ed1e380e0edbcbd\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:19:51 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2025/04/18 15:19:51 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "[W 2025-04-18 15:19:51,149] Trial 1 failed with parameters: {'learning_rate': 0.050914069782080844, 'max_depth': 3, 'subsample': 0.9, 'colsample_bytree': 0.5, 'min_child_weight': 6} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_7471/2029287172.py\", line 34, in fine_tuning\n",
      "    X_train_internal[num_cols] = num_pipeline.fit_transform(X_train_internal[num_cols])\n",
      "                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/utils/autologging_utils/safety.py\", line 483, in safe_patch_function\n",
      "    patch_function(call_original, *args, **kwargs)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/utils/autologging_utils/safety.py\", line 182, in patch_with_managed_run\n",
      "    result = patch_function(original, *args, **kwargs)\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/sklearn/__init__.py\", line 1655, in patched_fit\n",
      "    result = fit_impl(original, self, *args, **kwargs)\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/sklearn/__init__.py\", line 1431, in fit_mlflow\n",
      "    _log_posttraining_metadata(autologging_client, self, X, y_true, sample_weight)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/sklearn/__init__.py\", line 1564, in _log_posttraining_metadata\n",
      "    _log_model_with_except_handling(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        estimator,\n",
      "        ^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        registered_model_name=registered_model_name,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/sklearn/__init__.py\", line 1548, in _log_model_with_except_handling\n",
      "    return log_model(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/sklearn/__init__.py\", line 413, in log_model\n",
      "    return Model.log(\n",
      "           ~~~~~~~~~^\n",
      "        artifact_path=artifact_path,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<12 lines>...\n",
      "        metadata=metadata,\n",
      "        ^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/models/model.py\", line 855, in log\n",
      "    flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n",
      "    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/sklearn/__init__.py\", line 305, in save_model\n",
      "    inferred_reqs = mlflow.models.infer_pip_requirements(\n",
      "        model_data_path,\n",
      "        FLAVOR_NAME,\n",
      "        fallback=default_reqs,\n",
      "    )\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/utils/environment.py\", line 432, in infer_pip_requirements\n",
      "    return _infer_requirements(\n",
      "        model_uri, flavor, raise_on_error=raise_on_error, extra_env_vars=extra_env_vars\n",
      "    )\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/utils/requirements_utils.py\", line 511, in _infer_requirements\n",
      "    modules = _capture_imported_modules(model_uri, flavor, extra_env_vars=extra_env_vars)\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/utils/requirements_utils.py\", line 385, in _capture_imported_modules\n",
      "    _run_command(\n",
      "    ~~~~~~~~~~~~^\n",
      "        [\n",
      "        ^\n",
      "    ...<19 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/utils/requirements_utils.py\", line 252, in _run_command\n",
      "    stdout, stderr = proc.communicate()\n",
      "                     ~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/subprocess.py\", line 1221, in communicate\n",
      "    stdout, stderr = self._communicate(input, endtime, timeout)\n",
      "                     ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/subprocess.py\", line 2130, in _communicate\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/olist-freight/lib/python3.13/selectors.py\", line 398, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-18 15:19:51,152] Trial 1 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run chill-ray-267 at: http://localhost:5000/#/experiments/535394779431182411/runs/811a7ade2c9044ec8c0a993d20af8fe1\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m avg_mse\n\u001b[32m     64\u001b[39m study = opt.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfine_tuning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/optuna/study/study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/optuna/study/_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/optuna/study/_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mfine_tuning\u001b[39m\u001b[34m(trial, k)\u001b[39m\n\u001b[32m     31\u001b[39m num_cols = X_train_internal.select_dtypes(exclude=[\u001b[33m'\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m'\u001b[39m]).columns\n\u001b[32m     33\u001b[39m X_train_internal[cat_cols] = cat_pipeline.fit_transform(X_train_internal[cat_cols], y_train_internal)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m X_train_internal[num_cols] = \u001b[43mnum_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_internal\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnum_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m X_test_internal[cat_cols] = cat_pipeline.transform(X_test_internal[cat_cols])\n\u001b[32m     37\u001b[39m X_test_internal[num_cols] = num_pipeline.transform(X_test_internal[num_cols])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/utils/autologging_utils/safety.py:483\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m call_original = update_wrapper_extended(call_original, original)\n\u001b[32m    481\u001b[39m event_logger.log_patch_function_start(args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m session.state = \u001b[33m\"\u001b[39m\u001b[33msucceeded\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    486\u001b[39m event_logger.log_patch_function_success(args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/utils/autologging_utils/safety.py:182\u001b[39m, in \u001b[36mwith_managed_run.<locals>.patch_with_managed_run\u001b[39m\u001b[34m(original, *args, **kwargs)\u001b[39m\n\u001b[32m    179\u001b[39m     managed_run = create_managed_run()\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     result = \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[39;00m\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# that runs are terminated if a user prematurely interrupts training execution\u001b[39;00m\n\u001b[32m    186\u001b[39m     \u001b[38;5;66;03m# (e.g. via sigint / ctrl-c)\u001b[39;00m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m managed_run:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/sklearn/__init__.py:1655\u001b[39m, in \u001b[36m_autolog.<locals>.patched_fit\u001b[39m\u001b[34m(fit_impl, allow_children_patch, original, self, *args, **kwargs)\u001b[39m\n\u001b[32m   1651\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m t.should_log():\n\u001b[32m   1652\u001b[39m     \u001b[38;5;66;03m# In `fit_mlflow` call, it will also call metric API for computing training metrics\u001b[39;00m\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# so we need temporarily disable the post_training_metrics patching.\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _AUTOLOGGING_METRICS_MANAGER.disable_log_post_training_metrics():\n\u001b[32m-> \u001b[39m\u001b[32m1655\u001b[39m         result = \u001b[43mfit_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m should_log_post_training_metrics:\n\u001b[32m   1657\u001b[39m         _AUTOLOGGING_METRICS_MANAGER.register_model(\n\u001b[32m   1658\u001b[39m             \u001b[38;5;28mself\u001b[39m, mlflow.active_run().info.run_id\n\u001b[32m   1659\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/sklearn/__init__.py:1431\u001b[39m, in \u001b[36m_autolog.<locals>.fit_mlflow\u001b[39m\u001b[34m(original, self, *args, **kwargs)\u001b[39m\n\u001b[32m   1429\u001b[39m params_logging_future = autologging_client.flush(synchronous=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1430\u001b[39m fit_output = original(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1431\u001b[39m \u001b[43m_log_posttraining_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mautologging_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1432\u001b[39m autologging_client.flush(synchronous=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1433\u001b[39m params_logging_future.await_completion()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/sklearn/__init__.py:1564\u001b[39m, in \u001b[36m_autolog.<locals>._log_posttraining_metadata\u001b[39m\u001b[34m(autologging_client, estimator, X, y, sample_weight)\u001b[39m\n\u001b[32m   1554\u001b[39m     input_example, signature = resolve_input_example_and_signature(\n\u001b[32m   1555\u001b[39m         get_input_example,\n\u001b[32m   1556\u001b[39m         infer_model_signature,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1559\u001b[39m         _logger,\n\u001b[32m   1560\u001b[39m     )\n\u001b[32m   1561\u001b[39m     registered_model_name = get_autologging_config(\n\u001b[32m   1562\u001b[39m         FLAVOR_NAME, \u001b[33m\"\u001b[39m\u001b[33mregistered_model_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1563\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1564\u001b[39m     \u001b[43m_log_model_with_except_handling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1566\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1567\u001b[39m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1571\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1573\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_parameter_search_estimator(estimator):\n\u001b[32m   1574\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[33m\"\u001b[39m\u001b[33mbest_estimator_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m log_models:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/sklearn/__init__.py:1548\u001b[39m, in \u001b[36m_autolog.<locals>._log_posttraining_metadata.<locals>._log_model_with_except_handling\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1546\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_log_model_with_except_handling\u001b[39m(*args, **kwargs):\n\u001b[32m   1547\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1548\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1549\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _SklearnCustomModelPicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1550\u001b[39m         _logger.warning(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/sklearn/__init__.py:413\u001b[39m, in \u001b[36mlog_model\u001b[39m\u001b[34m(sk_model, artifact_path, conda_env, code_paths, serialization_format, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS.format(package_name=\u001b[33m\"\u001b[39m\u001b[33mscikit-learn\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_model\u001b[39m(\n\u001b[32m    336\u001b[39m     sk_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     metadata=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    349\u001b[39m ):\n\u001b[32m    350\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[33;03m    Log a scikit-learn model as an MLflow artifact for the current run. Produces an MLflow Model\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[33;03m    containing the following flavors:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    411\u001b[39m \n\u001b[32m    412\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43msklearn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43msk_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43msk_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/models/model.py:855\u001b[39m, in \u001b[36mModel.log\u001b[39m\u001b[34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, **kwargs)\u001b[39m\n\u001b[32m    846\u001b[39m     prompts = [pr.uri \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pr, Prompt) \u001b[38;5;28;01melse\u001b[39;00m pr \u001b[38;5;28;01mfor\u001b[39;00m pr \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m    847\u001b[39m mlflow_model = \u001b[38;5;28mcls\u001b[39m(\n\u001b[32m    848\u001b[39m     artifact_path=artifact_path,\n\u001b[32m    849\u001b[39m     run_id=run_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m    853\u001b[39m     prompts=prompts,\n\u001b[32m    854\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m855\u001b[39m \u001b[43mflavor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result in\u001b[39;00m\n\u001b[32m    857\u001b[39m \u001b[38;5;66;03m# __pycache__ directories being created in the model directory.\u001b[39;00m\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pycache \u001b[38;5;129;01min\u001b[39;00m Path(local_path).rglob(\u001b[33m\"\u001b[39m\u001b[33m__pycache__\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/sklearn/__init__.py:305\u001b[39m, in \u001b[36msave_model\u001b[39m\u001b[34m(sk_model, path, conda_env, code_paths, mlflow_model, serialization_format, signature, input_example, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001b[39m\n\u001b[32m    302\u001b[39m     default_reqs = get_default_pip_requirements(include_cloudpickle)\n\u001b[32m    303\u001b[39m     \u001b[38;5;66;03m# To ensure `_load_pyfunc` can successfully load the model during the dependency\u001b[39;00m\n\u001b[32m    304\u001b[39m     \u001b[38;5;66;03m# inference, `mlflow_model.save` must be called beforehand to save an MLmodel file.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m     inferred_reqs = \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfer_pip_requirements\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_data_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[43mFLAVOR_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m     default_reqs = \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(inferred_reqs).union(default_reqs))\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/utils/environment.py:432\u001b[39m, in \u001b[36minfer_pip_requirements\u001b[39m\u001b[34m(model_uri, flavor, fallback, timeout, extra_env_vars)\u001b[39m\n\u001b[32m    428\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m _infer_requirements(\n\u001b[32m    429\u001b[39m                 model_uri, flavor, raise_on_error=raise_on_error, extra_env_vars=extra_env_vars\n\u001b[32m    430\u001b[39m             )\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_infer_requirements\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_env_vars\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_env_vars\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    436\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_error \u001b[38;5;129;01mor\u001b[39;00m (fallback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/utils/requirements_utils.py:511\u001b[39m, in \u001b[36m_infer_requirements\u001b[39m\u001b[34m(model_uri, flavor, raise_on_error, extra_env_vars)\u001b[39m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _PYPI_PACKAGE_INDEX \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    509\u001b[39m     _PYPI_PACKAGE_INDEX = _load_pypi_package_index()\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m modules = \u001b[43m_capture_imported_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_env_vars\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_env_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m packages = _flatten([_MODULES_TO_PACKAGES.get(module, []) \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m modules])\n\u001b[32m    513\u001b[39m packages = \u001b[38;5;28mmap\u001b[39m(_normalize_package_name, packages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/utils/requirements_utils.py:385\u001b[39m, in \u001b[36m_capture_imported_modules\u001b[39m\u001b[34m(model_uri, flavor, record_full_module, extra_env_vars)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _capture_modules\n\u001b[32m    384\u001b[39m error_file = os.path.join(tmpdir, \u001b[33m\"\u001b[39m\u001b[33merror.txt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m \u001b[43m_run_command\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_capture_modules\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__file__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m--model-path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m--flavor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m--output-file\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m--error-file\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m--sys-path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43mrecord_full_module_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocess_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmain_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_MLFLOW_IN_CAPTURE_MODULE_PROCESS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_env_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(error_file):\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(error_file) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/utils/requirements_utils.py:252\u001b[39m, in \u001b[36m_run_command\u001b[39m\u001b[34m(cmd, timeout_seconds, env)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    251\u001b[39m     timer.start()\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     stdout, stderr = \u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m     stdout = stdout.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    254\u001b[39m     stderr = stderr.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/subprocess.py:1221\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1218\u001b[39m     endtime = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     stdout, stderr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1223\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1224\u001b[39m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[32m   1225\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/subprocess.py:2130\u001b[39m, in \u001b[36mPopen._communicate\u001b[39m\u001b[34m(self, input, endtime, orig_timeout)\u001b[39m\n\u001b[32m   2123\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout,\n\u001b[32m   2124\u001b[39m                         stdout, stderr,\n\u001b[32m   2125\u001b[39m                         skip_check_and_raise=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2126\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[32m   2127\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2128\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfailed to raise TimeoutExpired.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2130\u001b[39m ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2131\u001b[39m \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[32m   2133\u001b[39m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[32m   2134\u001b[39m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/selectors.py:398\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    396\u001b[39m ready = []\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def fine_tuning(trial, k=5):\n",
    "    # tuning\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 10)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1, step=0.1)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1, step=0.1)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 1, 10)\n",
    "\n",
    "    folds = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    absolute_errors = list()\n",
    "    squared_errors = list()\n",
    "    r2 = list()\n",
    "\n",
    "    for k, (train_index, test_index) in enumerate(folds.split(X, y)):\n",
    "        \n",
    "        print(\"#\"*10 + f\" Fold: {k+1} \" + \"#\"*10)\n",
    "        \n",
    "        X_train_internal, y_train_internal = X.iloc[train_index, :], y.iloc[train_index]\n",
    "        X_test_internal, y_test_internal = X.iloc[test_index, :], y.iloc[test_index]\n",
    "\n",
    "        encoder = CatBoostEncoder()\n",
    "        \n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "        cat_pipeline = Pipeline([('encoder', encoder), ('imputer', cat_imputer)])\n",
    "        num_pipeline = Pipeline([('imputer', num_imputer)])\n",
    "\n",
    "        cat_cols = X_train_internal.select_dtypes(include=['object']).columns\n",
    "        num_cols = X_train_internal.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "        X_train_internal[cat_cols] = cat_pipeline.fit_transform(X_train_internal[cat_cols], y_train_internal)\n",
    "        X_train_internal[num_cols] = num_pipeline.fit_transform(X_train_internal[num_cols])\n",
    "\n",
    "        X_test_internal[cat_cols] = cat_pipeline.transform(X_test_internal[cat_cols])\n",
    "        X_test_internal[num_cols] = num_pipeline.transform(X_test_internal[num_cols])\n",
    "\n",
    "        model_XGBoost.fit(X_train_internal, y_train_internal)\n",
    "        y_pred = model_XGBoost.predict(X_test_internal)\n",
    "        r2score = r2_score(y_test_internal, y_pred)\n",
    "        mse = mean_squared_error(y_test_internal, y_pred)\n",
    "        mae = mean_absolute_error(y_test_internal, y_pred)\n",
    "\n",
    "        absolute_errors.append(mae)\n",
    "        squared_errors.append(mse)\n",
    "        r2.append(r2score)\n",
    "\n",
    "    \n",
    "    absolute_errors = np.array(absolute_errors)\n",
    "    squared_errors = np.array(squared_errors)\n",
    "    r2 = np.array(r2)\n",
    "\n",
    "    avg_mae = np.mean(absolute_errors)\n",
    "    avg_mse = np.mean(squared_errors)\n",
    "    avg_r2 = np.mean(r2)\n",
    "\n",
    "    std_mae = np.std(absolute_errors)\n",
    "    std_mse = np.std(squared_errors)\n",
    "    std_r2 = np.std(r2)\n",
    "\n",
    "    return avg_mse\n",
    "\n",
    "study = opt.create_study(direction='minimize')\n",
    "study.optimize(fine_tuning, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ee732",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.logging.set_verbosity(opt.logging.ERROR)\n",
    "\n",
    "def champion_callback(study, frozen_trial):\n",
    "    winner = study.user_attrs.get(\"winner\", None)\n",
    "\n",
    "    if study.best_value and winner != study.best_value:\n",
    "      study.set_user_attr(\"winner\", study.best_value)\n",
    "      if winner:\n",
    "          improvement_percent = (abs(winner - study.best_value) / study.best_value) * 100\n",
    "          print(\n",
    "              f\"Trial {frozen_trial.number} achieved value: {frozen_trial.value} with \"\n",
    "              f\"{improvement_percent: .4f}% improvement\"\n",
    "          )\n",
    "      else:\n",
    "          print(f\"Initial trial {frozen_trial.number} achieved value: {frozen_trial.value}\")\n",
    "\n",
    "\n",
    "def fine_tuning_with_mlflow(trial, k=5):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # tuning\n",
    "        params = {\n",
    "            \"learning_rate\": trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n",
    "            \"max_depth\": trial.suggest_int('max_depth', 1, 10),\n",
    "            \"subsample\": trial.suggest_float('subsample', 0.5, 1, step=0.1),\n",
    "            \"colsample_bytree\": trial.suggest_float('colsample_bytree', 0.5, 1, step=0.1),\n",
    "            \"min_child_weight\": trial.suggest_int('min_child_weight', 1, 10)\n",
    "        }\n",
    "\n",
    "        folds = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "        absolute_errors = list()\n",
    "        squared_errors = list()\n",
    "        r2 = list()\n",
    "\n",
    "        mlflow.xgboost.autolog()\n",
    "        \n",
    "        for k, (train_index, test_index) in enumerate(folds.split(X, y)):\n",
    "            \n",
    "            print(\"#\"*10 + f\" Fold: {k+1} \" + \"#\"*10)\n",
    "            \n",
    "            X_train_internal, y_train_internal = X.iloc[train_index, :], y.iloc[train_index]\n",
    "            X_test_internal, y_test_internal = X.iloc[test_index, :], y.iloc[test_index]\n",
    "\n",
    "            encoder = CatBoostEncoder()\n",
    "            \n",
    "            cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "            num_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "            cat_pipeline = Pipeline([('encoder', encoder), ('imputer', cat_imputer)])\n",
    "            num_pipeline = Pipeline([('imputer', num_imputer)])\n",
    "\n",
    "            cat_cols = X_train_internal.select_dtypes(include=['object']).columns\n",
    "            num_cols = X_train_internal.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "            X_train_internal[cat_cols] = cat_pipeline.fit_transform(X_train_internal[cat_cols], y_train_internal)\n",
    "            X_train_internal[num_cols] = num_pipeline.fit_transform(X_train_internal[num_cols])\n",
    "\n",
    "            X_test_internal[cat_cols] = cat_pipeline.transform(X_test_internal[cat_cols])\n",
    "            X_test_internal[num_cols] = num_pipeline.transform(X_test_internal[num_cols])\n",
    "\n",
    "            model_XGBoost.fit(X_train_internal, y_train_internal)\n",
    "            y_pred = model_XGBoost.predict(X_test_internal)\n",
    "            \n",
    "            r2score = r2_score(y_test_internal, y_pred)\n",
    "            mse = mean_squared_error(y_test_internal, y_pred)\n",
    "            mae = mean_absolute_error(y_test_internal, y_pred)\n",
    "\n",
    "            absolute_errors.append(mae)\n",
    "            squared_errors.append(mse)\n",
    "            r2.append(r2score)\n",
    "            \n",
    "            # Registrar métricas do fold no MLflow\n",
    "            mlflow.log_metric(f\"Fold_{k + 1}_MAE\", mae)\n",
    "            mlflow.log_metric(f\"Fold_{k + 1}_MSE\", mse)\n",
    "            mlflow.log_metric(f\"Fold_{k + 1}_R2\", r2score)\n",
    "\n",
    "        \n",
    "        absolute_errors = np.array(absolute_errors)\n",
    "        squared_errors = np.array(squared_errors)\n",
    "        r2 = np.array(r2)\n",
    "\n",
    "        avg_mae = np.mean(absolute_errors)\n",
    "        avg_mse = np.mean(squared_errors)\n",
    "        avg_r2 = np.mean(r2)\n",
    "\n",
    "        std_mae = np.std(absolute_errors)\n",
    "        std_mse = np.std(squared_errors)\n",
    "        std_r2 = np.std(r2)\n",
    "        \n",
    "        # Registrar métricas médias no MLflow\n",
    "        mlflow.log_metric(\"Average_MAE\", avg_mae)\n",
    "        mlflow.log_metric(\"Average_MSE\", avg_mse)\n",
    "        mlflow.log_metric(\"Average_R2\", avg_r2)\n",
    "\n",
    "        mlflow.log_metric(\"Std_MAE\", std_mae)\n",
    "        mlflow.log_metric(\"Std_MSE\", std_mse)\n",
    "        mlflow.log_metric(\"Std_R2\", std_r2)\n",
    "        \n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "\n",
    "    return avg_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3bce2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:52:21 WARNING mlflow.utils.autologging_utils: MLflow xgboost autologging is known to be compatible with 1.4.2 <= xgboost <= 2.1.4, but the installed version is 3.0.0. If you encounter errors during autologging, try upgrading / downgrading xgboost to a compatible version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 1 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:52:22 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/04/18 15:52:25 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2025/04/18 15:52:25 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/04/18 15:56:31 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID b419428ac4074559ac3b9cad2c570fa9. Failed operations: [MlflowException(\"API request to http://localhost:5000/api/2.0/mlflow/runs/log-batch failed with exception HTTPConnectionPool(host=\\'localhost\\', port=5000): Max retries exceeded with url: /api/2.0/mlflow/runs/log-batch (Caused by ResponseError(\\'too many 500 error responses\\'))\")]')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 2 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 15:56:45 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/04/18 15:56:48 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2025/04/18 15:56:48 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/04/18 16:00:55 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID b419428ac4074559ac3b9cad2c570fa9. Failed operations: [MlflowException(\"API request to http://localhost:5000/api/2.0/mlflow/runs/log-batch failed with exception HTTPConnectionPool(host=\\'localhost\\', port=5000): Max retries exceeded with url: /api/2.0/mlflow/runs/log-batch (Caused by ResponseError(\\'too many 500 error responses\\'))\")]')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 3 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 16:01:09 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/04/18 16:01:12 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2025/04/18 16:01:12 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/04/18 16:05:18 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID b419428ac4074559ac3b9cad2c570fa9. Failed operations: [MlflowException(\"API request to http://localhost:5000/api/2.0/mlflow/runs/log-batch failed with exception HTTPConnectionPool(host=\\'localhost\\', port=5000): Max retries exceeded with url: /api/2.0/mlflow/runs/log-batch (Caused by ResponseError(\\'too many 500 error responses\\'))\")]')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 4 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/18 16:05:50 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/04/18 16:05:53 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2025/04/18 16:05:53 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run dashing-stag-211 at: http://localhost:5000/#/experiments/535394779431182411/runs/b419428ac4074559ac3b9cad2c570fa9\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n",
      "🏃 View run Optuna Fine-Tuning at: http://localhost:5000/#/experiments/535394779431182411/runs/db3195d711154d10a9fe83c60dc4550e\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/535394779431182411\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      6\u001b[39m study = opt.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Execute the hyperparameter optimization trials.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Note the addition of the `champion_callback` inclusion to control our logging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfine_tuning_with_mlflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchampion_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m mlflow.log_params(study.best_params)\n\u001b[32m     13\u001b[39m mlflow.log_metric(\u001b[33m\"\u001b[39m\u001b[33mbest_mse\u001b[39m\u001b[33m\"\u001b[39m, study.best_value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/optuna/study/study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/optuna/study/_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/optuna/study/_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mfine_tuning_with_mlflow\u001b[39m\u001b[34m(trial, k)\u001b[39m\n\u001b[32m     56\u001b[39m num_cols = X_train_internal.select_dtypes(exclude=[\u001b[33m'\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m'\u001b[39m]).columns\n\u001b[32m     58\u001b[39m X_train_internal[cat_cols] = cat_pipeline.fit_transform(X_train_internal[cat_cols], y_train_internal)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m X_train_internal[num_cols] = \u001b[43mnum_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_internal\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnum_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m X_test_internal[cat_cols] = cat_pipeline.transform(X_test_internal[cat_cols])\n\u001b[32m     62\u001b[39m X_test_internal[num_cols] = num_pipeline.transform(X_test_internal[num_cols])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/utils/autologging_utils/safety.py:483\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m call_original = update_wrapper_extended(call_original, original)\n\u001b[32m    481\u001b[39m event_logger.log_patch_function_start(args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m session.state = \u001b[33m\"\u001b[39m\u001b[33msucceeded\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    486\u001b[39m event_logger.log_patch_function_success(args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/utils/autologging_utils/safety.py:182\u001b[39m, in \u001b[36mwith_managed_run.<locals>.patch_with_managed_run\u001b[39m\u001b[34m(original, *args, **kwargs)\u001b[39m\n\u001b[32m    179\u001b[39m     managed_run = create_managed_run()\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     result = \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[39;00m\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# that runs are terminated if a user prematurely interrupts training execution\u001b[39;00m\n\u001b[32m    186\u001b[39m     \u001b[38;5;66;03m# (e.g. via sigint / ctrl-c)\u001b[39;00m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m managed_run:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/sklearn/__init__.py:1655\u001b[39m, in \u001b[36m_autolog.<locals>.patched_fit\u001b[39m\u001b[34m(fit_impl, allow_children_patch, original, self, *args, **kwargs)\u001b[39m\n\u001b[32m   1651\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m t.should_log():\n\u001b[32m   1652\u001b[39m     \u001b[38;5;66;03m# In `fit_mlflow` call, it will also call metric API for computing training metrics\u001b[39;00m\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# so we need temporarily disable the post_training_metrics patching.\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _AUTOLOGGING_METRICS_MANAGER.disable_log_post_training_metrics():\n\u001b[32m-> \u001b[39m\u001b[32m1655\u001b[39m         result = \u001b[43mfit_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m should_log_post_training_metrics:\n\u001b[32m   1657\u001b[39m         _AUTOLOGGING_METRICS_MANAGER.register_model(\n\u001b[32m   1658\u001b[39m             \u001b[38;5;28mself\u001b[39m, mlflow.active_run().info.run_id\n\u001b[32m   1659\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/sklearn/__init__.py:1433\u001b[39m, in \u001b[36m_autolog.<locals>.fit_mlflow\u001b[39m\u001b[34m(original, self, *args, **kwargs)\u001b[39m\n\u001b[32m   1431\u001b[39m _log_posttraining_metadata(autologging_client, \u001b[38;5;28mself\u001b[39m, X, y_true, sample_weight)\n\u001b[32m   1432\u001b[39m autologging_client.flush(synchronous=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1433\u001b[39m \u001b[43mparams_logging_future\u001b[49m\u001b[43m.\u001b[49m\u001b[43mawait_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1434\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fit_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/site-packages/mlflow/utils/autologging_utils/client.py:65\u001b[39m, in \u001b[36mRunOperations.await_completion\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._operation_futures:\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     67\u001b[39m         failed_operations.append(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/olist-freight/lib/python3.13/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "run_name = 'Optuna Fine-Tuning'\n",
    "\n",
    "# Initiate the parent run and call the hyperparameter tuning child run logic\n",
    "with mlflow.start_run(run_name=run_name, nested=True):\n",
    "  # Initialize the Optuna study\n",
    "  study = opt.create_study(direction=\"minimize\")\n",
    "  \n",
    "  # Execute the hyperparameter optimization trials.\n",
    "  # Note the addition of the `champion_callback` inclusion to control our logging\n",
    "  study.optimize(fine_tuning_with_mlflow, n_trials=10, callbacks=[champion_callback])\n",
    "  \n",
    "  mlflow.log_params(study.best_params)\n",
    "  mlflow.log_metric(\"best_mse\", study.best_value)\n",
    "  mlflow.log_metric(\"best_rmse\", math.sqrt(study.best_value))\n",
    "\n",
    "  # Log tags\n",
    "  mlflow.set_tags(\n",
    "      tags={\n",
    "          \"project\": \"Freight Value Prediction\",\n",
    "          \"optimizer_engine\": \"optuna\",\n",
    "          \"model_family\": \"xgboost\",\n",
    "          \"feature_set_version\": 1,\n",
    "      }\n",
    "  )\n",
    "  \n",
    "  # Log a fit model instance\n",
    "  model = XGBRegressor(\n",
    "        n_estimators=1000,\n",
    "        n_jobs=-1,\n",
    "        random_state=0,\n",
    "        **study.best_params\n",
    "    )\n",
    "  \n",
    "  # Log a fit model instance\n",
    "  model = model.train(study.best_params, X_train)\n",
    "  \n",
    "  artifact_path = \"model\"\n",
    "\n",
    "  mlflow.xgboost.log_model(\n",
    "      xgb_model=model,\n",
    "      artifact_path=artifact_path,\n",
    "      input_example=X_train[[0]],\n",
    "      model_format=\"ubj\",\n",
    "      metadata={\"model_data_version\": 1},\n",
    "  )\n",
    "\n",
    "  # Get the logged model uri so that we can load it from the artifact store\n",
    "  model_uri = mlflow.get_artifact_uri(artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a9285",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate': 0.008335068262687652, 'max_depth': 5, 'subsample': 0.6, 'colsample_bytree': 0.9, 'min_child_weight': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26068523",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_XGBoost = XGBRegressor(n_estimators=1000, n_jobs=-1, random_state=0, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d3672a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 1 ##########\n",
      "MAE: 3.785\n",
      "MSE: 64.887\n",
      "R2: 0.736\n",
      "########## Fold: 2 ##########\n",
      "MAE: 3.925\n",
      "MSE: 67.987\n",
      "R2: 0.743\n",
      "########## Fold: 3 ##########\n",
      "MAE: 3.843\n",
      "MSE: 62.634\n",
      "R2: 0.747\n",
      "########## Fold: 4 ##########\n",
      "MAE: 3.821\n",
      "MSE: 72.702\n",
      "R2: 0.732\n",
      "########## Fold: 5 ##########\n",
      "MAE: 3.774\n",
      "MSE: 55.732\n",
      "R2: 0.761\n",
      "##### Displaying Average of Obtained Metrics : #####\n",
      "Average MAE: 3.829 +/- 0.054\n",
      "Average MSE: 64.788 +/- 5.648\n",
      "Average R2: 0.744 +/- 0.010\n"
     ]
    }
   ],
   "source": [
    "cross_validation_with_mlflow(X, y, model_XGBoost, k=5, model_name='XGBoost Fine-Tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb63e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def feature_engineering(X_train, X_test):\n",
    "\n",
    "#     X_train['volume'] = X_train['product_length_cm'] * X_train['product_height_cm'] * X_train['product_width_cm']\n",
    "#     X_test['volume'] = X_test['product_length_cm'] * X_test['product_height_cm'] * X_test['product_width_cm']\n",
    "\n",
    "#     # other important features\n",
    "\n",
    "#     return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7024062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_validation(X, y, model, k):\n",
    "#     folds = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "#     absolute_errors = list()\n",
    "#     squared_errors = list()\n",
    "#     r2 = list()\n",
    "\n",
    "#     for k, (train_index, test_index) in enumerate(folds.split(X, y)):\n",
    "        \n",
    "#         print(\"#\"*10 + f\" Fold: {k+1} \" + \"#\"*10)\n",
    "        \n",
    "#         X_train_internal, y_train_internal = X.iloc[train_index, :], y.iloc[train_index]\n",
    "#         X_test_internal, y_test_internal = X.iloc[test_index, :], y.iloc[test_index]\n",
    "\n",
    "#         encoder = CatBoostEncoder()\n",
    "        \n",
    "#         cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "#         num_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "#         cat_pipeline = Pipeline([('encoder', encoder), ('imputer', cat_imputer)])\n",
    "#         num_pipeline = Pipeline([('imputer', num_imputer)])\n",
    "\n",
    "#         X_train_internal, X_test_internal = feature_engineering(X_train_internal, X_test_internal)\n",
    "\n",
    "#         cat_cols = X_train_internal.select_dtypes(include=['object']).columns\n",
    "#         num_cols = X_train_internal.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "#         X_train_internal[cat_cols] = cat_pipeline.fit_transform(X_train_internal[cat_cols], y_train_internal)\n",
    "#         X_train_internal[num_cols] = num_pipeline.fit_transform(X_train_internal[num_cols])\n",
    "\n",
    "#         X_test_internal[cat_cols] = cat_pipeline.transform(X_test_internal[cat_cols])\n",
    "#         X_test_internal[num_cols] = num_pipeline.transform(X_test_internal[num_cols])\n",
    "\n",
    "#         model.fit(X_train_internal, y_train_internal)\n",
    "#         y_pred = model.predict(X_test_internal)\n",
    "#         r2score = r2_score(y_test_internal, y_pred)\n",
    "#         mse = mean_squared_error(y_test_internal, y_pred)\n",
    "#         mae = mean_absolute_error(y_test_internal, y_pred)\n",
    "\n",
    "#         absolute_errors.append(mae)\n",
    "#         squared_errors.append(mse)\n",
    "#         r2.append(r2score)\n",
    "\n",
    "#         print(f'MAE: {mae:.3f}')\n",
    "#         print(f'MSE: {mse:.3f}')\n",
    "#         print(f'R2: {r2score:.3f}')\n",
    "    \n",
    "#     absolute_errors = np.array(absolute_errors)\n",
    "#     squared_errors = np.array(squared_errors)\n",
    "#     r2 = np.array(r2)\n",
    "\n",
    "#     avg_mae = np.mean(absolute_errors)\n",
    "#     avg_mse = np.mean(squared_errors)\n",
    "#     avg_r2 = np.mean(r2)\n",
    "\n",
    "#     std_mae = np.std(absolute_errors)\n",
    "#     std_mse = np.std(squared_errors)\n",
    "#     std_r2 = np.std(r2)\n",
    "\n",
    "#     print(\"#\"*5 + f\" Displaying Average of Obtained Metrics : \" + \"#\"*5)\n",
    "#     print(f\"Average MAE: {avg_mae:.3f} +/- {std_mae:.3f}\")\n",
    "#     print(f'Average MSE: {avg_mse:.3f} +/- {std_mse:.3f}')\n",
    "#     print(f'Average R2: {avg_r2:.3f} +/- {std_r2:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74725c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold: 1 ##########\n",
      "MAE: 5.664\n",
      "MSE: 120.227\n",
      "R2: 0.511\n",
      "########## Fold: 2 ##########\n",
      "MAE: 5.827\n",
      "MSE: 128.344\n",
      "R2: 0.515\n",
      "########## Fold: 3 ##########\n",
      "MAE: 5.773\n",
      "MSE: 119.646\n",
      "R2: 0.517\n",
      "########## Fold: 4 ##########\n",
      "MAE: 5.715\n",
      "MSE: 136.550\n",
      "R2: 0.497\n",
      "########## Fold: 5 ##########\n",
      "MAE: 5.612\n",
      "MSE: 108.576\n",
      "R2: 0.535\n",
      "##### Displaying Average of Obtained Metrics : #####\n",
      "Average MAE: 5.718 +/- 0.076\n",
      "Average MSE: 122.669 +/- 9.366\n",
      "Average R2: 0.515 +/- 0.012\n"
     ]
    }
   ],
   "source": [
    "# cross_validation(X, y, model_LightGBM, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2b7c11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olist-freight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
